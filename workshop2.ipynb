{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6c3b63-e014-4574-a909-c294c5574f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating a simple Series\n",
    "data = [10, 20, 30, 40]\n",
    "series = pd.Series(data)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85afbe2-9ba0-402a-beb7-0eb929daa6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=3, step=1)\n",
      "a    10\n",
      "b    20\n",
      "c    30\n",
      "dtype: int64\n",
      "2023-01-01    10\n",
      "2023-01-02    20\n",
      "2023-01-03    30\n",
      "Freq: D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Default Index\n",
    "import pandas as pd\n",
    "series = pd.Series([10, 20, 30])\n",
    "print(series.index)\n",
    "# Output: RangeIndex(start=0, stop=3, step=1)\n",
    "# User Defined:\n",
    "series = pd.Series([10, 20, 30],index=['a','b','c'])\n",
    "print(series)\n",
    "# Output:\n",
    "# a 10\n",
    "# b 20\n",
    "# c 30\n",
    "#datestime index\n",
    "dates = pd.date_range('2023-01-01', periods=3)\n",
    "series = pd.Series([10, 20, 30], index=dates)\n",
    "print(series)\n",
    "# Output:\n",
    "# 2023-01-01 10\n",
    "# 2023-01-02 20\n",
    "# 2023-01-03 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f334d310-7e3d-4ab1-91ba-c1791be0b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03'], dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "#Access\n",
    "print(series.index)\n",
    "# Set or Reset Index\n",
    "series.index = ['x', 'y', 'z'] # Series\n",
    "# For DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2]}, index=['row1', 'row2'])\n",
    "df.reset_index(inplace=True)\n",
    "# Converts the index into a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "382cdf30-f2d7-4419-8daa-fd5291244c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bob</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Product A</th>\n",
       "      <td>I liked it.</td>\n",
       "      <td>Pretty good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product B</th>\n",
       "      <td>It was awful.</td>\n",
       "      <td>Bland.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bob           Sue\n",
       "Product A    I liked it.  Pretty good.\n",
       "Product B  It was awful.        Bland."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming in-built data structures-DataFrame\n",
    "#Style-1\n",
    "import pandas as pd\n",
    "pd.DataFrame({'Bob': ['I liked it.','It was awful'], 'Sue': ['Pretty good.', 'Bland.']})\n",
    "#Style-2\n",
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']},\n",
    "\n",
    "index=['Product A', 'Product B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f7a0ac9-87ff-41b8-830b-aa7a85303cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   City    3 non-null      object\n",
      " 2   age     3 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#Importing Data from file\n",
    "import pandas as pd\n",
    "# path to your dataset must be given to built in read_csv(\"Your path\") function.\n",
    "dataset = pd.read_csv(\"output.csv\")\n",
    "dataset.head()\n",
    "dataset.tail()\n",
    "dataset.info()\n",
    "# Run the above code and observe the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90753951-e718-4473-9f89-6eddc9133ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bob</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Product A</th>\n",
       "      <td>I liked it.</td>\n",
       "      <td>Pretty good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product B</th>\n",
       "      <td>It was awful</td>\n",
       "      <td>Bland.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Bob           Sue\n",
       "Product A   I liked it.  Pretty good.\n",
       "Product B  It was awful        Bland."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming in-built data structures-DataFrame\n",
    "#Style-1\n",
    "import pandas as pd\n",
    "pd.DataFrame({'Bob': ['I liked it.','It was awful'], 'Sue': ['Pretty good.','Bland.']})\n",
    "#Style-2\n",
    "pd.DataFrame({'Bob': ['I liked it.','It was awful'], 'Sue': ['Pretty good.','Bland.']}, index=['Product A', 'Product B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af0a875b-20c8-4317-acc5-165ac587aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles'],\n",
    "        'age':['23', '34', '32']}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# Confirm the operation\n",
    "print(\"Data written to output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab08eca-4c74-404c-a59a-db52654ec303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Salary\n",
      "0  Alice   25   50000\n",
      "1    Bob   30   60000\n",
      "      Name  Age  Salary\n",
      "2  Charlie   35   70000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   Age     3 non-null      int64 \n",
      " 2   Salary  3 non-null      int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "        Age   Salary\n",
      "count   3.0      3.0\n",
      "mean   30.0  60000.0\n",
      "std     5.0  10000.0\n",
      "min    25.0  50000.0\n",
      "25%    27.5  55000.0\n",
      "50%    30.0  60000.0\n",
      "75%    32.5  65000.0\n",
      "max    35.0  70000.0\n",
      "The DataFrame has 3 rows and 3 columns.\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "Name: Age, dtype: int64\n",
      "Name      Alice\n",
      "Age          25\n",
      "Salary    50000\n",
      "Name: 0, dtype: object\n",
      "      Name  Age  Salary\n",
      "2  Charlie   35   70000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [50000, 60000, 70000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# View the first two rows\n",
    "print(df.head(2))\n",
    "\n",
    "# View the last row\n",
    "print(df.tail(1))\n",
    "\n",
    "# DataFrame information\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check dimensions of the DataFrame\n",
    "print(f\"The DataFrame has {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "# Access the 'Age' column\n",
    "print(df['Age'])\n",
    "\n",
    "# Select rows by numerical index\n",
    "print(df.iloc[0])  # First row\n",
    "\n",
    "# Select rows by condition\n",
    "print(df.loc[df['Age'] > 30])  # Rows where Age > 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f45deb1-4db8-4c2a-a4a7-82dbfe4d374a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    3 non-null      object \n",
      " 1   Age     2 non-null      float64\n",
      " 2   Salary  3 non-null      int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, None],\n",
    "    'Salary': [50000, 60000, 55000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06a0cc66-c643-4e01-bf15-87951581ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Age   Salary\n",
      "count   2.000000      3.0\n",
      "mean   27.500000  55000.0\n",
      "std     3.535534   5000.0\n",
      "min    25.000000  50000.0\n",
      "25%    26.250000  52500.0\n",
      "50%    27.500000  55000.0\n",
      "75%    28.750000  57500.0\n",
      "max    30.000000  60000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, None],\n",
    "    'Salary': [50000, 60000, 55000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check summary statistics\n",
    "print(df.describe())  # Generate descriptive statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "443f689b-194e-4c28-858e-5f6ab617abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Salary\n",
      "1      Bob   30   60000\n",
      "2  Charlie   35   70000\n",
      "      Name  Salary\n",
      "0    Alice   50000\n",
      "1      Bob   60000\n",
      "2  Charlie   70000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [50000, 60000, 70000]\n",
    "})\n",
    "\n",
    "# Filter rows where Age > 28\n",
    "filtered_rows = df[df['Age'] > 28]\n",
    "print(filtered_rows)\n",
    "\n",
    "# Select Specific Columns\n",
    "# Select only 'Name' and 'Salary' columns\n",
    "selected_columns = df[['Name', 'Salary']]\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02ac911b-b2cb-48b5-a6d8-22a917a94913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame without 'Salary' column:\n",
      "      Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n",
      "\n",
      "DataFrame without row index 1 (Bob):\n",
      "      Name  Age  Salary\n",
      "0    Alice   25   50000\n",
      "2  Charlie   35   70000\n",
      "\n",
      "DataFrame with 'Bonus' column:\n",
      "      Name  Age  Salary   Bonus\n",
      "0    Alice   25   50000  5000.0\n",
      "1      Bob   30   60000  6000.0\n",
      "2  Charlie   35   70000  7000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [50000, 60000, 70000]\n",
    "})\n",
    "\n",
    "# Drop the 'Salary' column\n",
    "df_without_salary = df.drop(columns=['Salary'])\n",
    "print(\"DataFrame without 'Salary' column:\")\n",
    "print(df_without_salary)\n",
    "\n",
    "# Drop the row with index 1 (Bob)\n",
    "df_without_row = df.drop(index=1)\n",
    "print(\"\\nDataFrame without row index 1 (Bob):\")\n",
    "print(df_without_row)\n",
    "\n",
    "# Add a new column for Bonus\n",
    "df['Bonus'] = df['Salary'] * 0.1\n",
    "print(\"\\nDataFrame with 'Bonus' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5391af88-df4c-4f61-8cd1-1a0b3b30b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Iris Dataset:\n",
      "sepal length (cm)    15\n",
      "sepal width (cm)     15\n",
      "petal length (cm)    19\n",
      "petal width (cm)     15\n",
      "target               19\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "# Introduce missing values randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "mask = np.random.rand(*iris_df.shape) < 0.1  # 10%\n",
    "iris_df[mask] = np.nan\n",
    "\n",
    "# Print the count of missing values in each column\n",
    "print(\"Missing Values in Iris Dataset:\")\n",
    "print(iris_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fe0a7a3-29e0-4584-b237-a32c20ff4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values with forward fill (ffill), mean, median, and 0\n",
    "iris_df_ffill = iris_df.ffill()\n",
    "iris_df_mean = iris_df.fillna(iris_df.mean())\n",
    "iris_df_median = iris_df.fillna(iris_df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01815bc-1816-4c26-b159-fa716afda67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after Filling Missing Values:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               NaN                1.4               0.2   \n",
      "2                NaN               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  sepal length (cm)_ffill  sepal width (cm)_ffill  \\\n",
      "0     0.0                      5.1                     3.5   \n",
      "1     0.0                      4.9                     3.5   \n",
      "2     0.0                      4.9                     3.2   \n",
      "3     0.0                      4.6                     3.1   \n",
      "4     0.0                      5.0                     3.6   \n",
      "\n",
      "   petal length (cm)_ffill  petal width (cm)_ffill  target_ffill  ...  \\\n",
      "0                      1.4                     0.2           0.0  ...   \n",
      "1                      1.4                     0.2           0.0  ...   \n",
      "2                      1.3                     0.2           0.0  ...   \n",
      "3                      1.5                     0.2           0.0  ...   \n",
      "4                      1.4                     0.2           0.0  ...   \n",
      "\n",
      "   sepal length (cm)_median  sepal width (cm)_median  \\\n",
      "0                       5.1                      3.5   \n",
      "1                       4.9                      3.0   \n",
      "2                       5.8                      3.2   \n",
      "3                       4.6                      3.1   \n",
      "4                       5.0                      3.6   \n",
      "\n",
      "   petal length (cm)_median  petal width (cm)_median  target_median  \\\n",
      "0                       1.4                      0.2            0.0   \n",
      "1                       1.4                      0.2            0.0   \n",
      "2                       1.3                      0.2            0.0   \n",
      "3                       1.5                      0.2            0.0   \n",
      "4                       1.4                      0.2            0.0   \n",
      "\n",
      "   sepal length (cm)_zero  sepal width (cm)_zero  petal length (cm)_zero  \\\n",
      "0                     5.1                    3.5                     1.4   \n",
      "1                     4.9                    0.0                     1.4   \n",
      "2                     0.0                    3.2                     1.3   \n",
      "3                     4.6                    3.1                     1.5   \n",
      "4                     5.0                    3.6                     1.4   \n",
      "\n",
      "   petal width (cm)_zero  target_zero  \n",
      "0                    0.2          0.0  \n",
      "1                    0.2          0.0  \n",
      "2                    0.2          0.0  \n",
      "3                    0.2          0.0  \n",
      "4                    0.2          0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "iris_df_zero = iris_df.fillna(0)\n",
    "# Expand iris_df with filled columns\n",
    "iris_df_expanded = pd.concat([iris_df, iris_df_ffill.add_suffix('_ffill'), iris_df_mean.add_suffix('_mean'),iris_df_median.add_suffix('_median'),iris_df_zero.add_suffix('_zero')], axis=1)\n",
    "# Display the head of the expanded DataFrame\n",
    "print(\"\\nDataset after Filling Missing Values:\")\n",
    "print(iris_df_expanded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6775a28f-74c2-4819-a187-407d37913cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After trimming whitespaces:\n",
      "    Name  Age\n",
      "0  Alice   25\n",
      "1    Bob   30\n",
      "\n",
      "\n",
      "After changing datatype:\n",
      "   Age\n",
      "0   25\n",
      "1   30\n",
      "2   35\n",
      "\n",
      "\n",
      "After renaming columns:\n",
      "  Full Name  Years\n",
      "0     Alice     25\n",
      "1       Bob     30\n",
      "\n",
      "\n",
      "After removing duplicates:\n",
      "    Name  Age\n",
      "0  Alice   25\n",
      "1    Bob   30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# -----------Trimming Whitespaces:----------------------------------\n",
    "#--------------------------------------------------------------------\n",
    "df = pd.DataFrame({'Name': ['Alice ', 'Bob '], 'Age': [25, 30]})\n",
    "df['Name'] = df['Name'].str.strip()\n",
    "print(\"After trimming whitespaces:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# -------------Changing Datatype:-------------------------------------\n",
    "#--------------------------------------------------------------------\n",
    "df = pd.DataFrame({'Age': ['25', '30', '35']})\n",
    "# Change 'Age' column data type to integer\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "print(\"After changing datatype:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# -------------Renaming Columns:-------------------------------------\n",
    "#--------------------------------------------------------------------\n",
    "# Rename columns\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n",
    "df = df.rename(columns={'Name': 'Full Name', 'Age': 'Years'})\n",
    "print(\"After renaming columns:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# --------------Removing Duplicates:-----------------------------------\n",
    "#--------------------------------------------------------------------\n",
    "# Remove duplicate rows\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Alice'], 'Age': [25, 30, 25]})\n",
    "df = df.drop_duplicates()\n",
    "print(\"After removing duplicates:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3600cf37-96b9-4878-abe1-2f1e229b1efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted DataFrame:\n",
      "City        Kathmandu  Pokhara\n",
      "Date                          \n",
      "2024-01-01         15       18\n",
      "2024-01-02         16       19\n",
      "\n",
      "\n",
      "Melted DataFrame:\n",
      "         Date       City  Temperature\n",
      "0  2024-01-01  Kathmandu           15\n",
      "1  2024-01-02  Kathmandu           16\n",
      "2  2024-01-01    Pokhara           18\n",
      "3  2024-01-02    Pokhara           19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#------------------Pivoting----------------------------------------\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],\n",
    "    'City': ['Kathmandu', 'Pokhara', 'Kathmandu', 'Pokhara'],\n",
    "    'Temperature': [15, 18, 16, 19]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot: Reshape data to show cities as columns\n",
    "pivoted_df = df.pivot(index='Date', columns='City', values='Temperature')\n",
    "print(\"Pivoted DataFrame:\")\n",
    "print(pivoted_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#---------------------------Melting-----------------------------------------\n",
    "#---------------------------------------------------------------------------\n",
    "# Melt: Convert wide data back to long format\n",
    "melted_df = pd.melt(pivoted_df.reset_index(), id_vars=['Date'],\n",
    "                    var_name='City', value_name='Temperature')\n",
    "\n",
    "print(\"Melted DataFrame:\")\n",
    "print(melted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37009b0b-c917-4be7-966d-3122780e08b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Iris DataFrame:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Min-Max Scaled Iris DataFrame:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222          0.625000           0.067797          0.041667\n",
      "1           0.166667          0.416667           0.067797          0.041667\n",
      "2           0.111111          0.500000           0.050847          0.041667\n",
      "3           0.083333          0.458333           0.084746          0.041667\n",
      "4           0.194444          0.666667           0.067797          0.041667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# Min-Max Scaling using Pandas\n",
    "iris_minmax_scaled = (iris_df - iris_df.min()) / (iris_df.max() - iris_df.min())\n",
    "\n",
    "print(\"Original Iris DataFrame:\")\n",
    "print(iris_df.head())\n",
    "print(\"\\nMin-Max Scaled Iris DataFrame:\")\n",
    "print(iris_minmax_scaled.head())  # Display scaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "297569d8-cfd5-407d-ba95-a7c9147ed070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Category_Ordinal\n",
      "0      Low                 1\n",
      "1   Medium                 2\n",
      "2     High                 3\n",
      "3      Low                 1\n",
      "4     High                 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with ordinal categories\n",
    "df = pd.DataFrame({'Category': ['Low', 'Medium', 'High', 'Low', 'High']})\n",
    "\n",
    "# Ordinal encoding using map\n",
    "ordinal_mapping = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "df['Category_Ordinal'] = df['Category'].map(ordinal_mapping)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1383c107-c645-4e9c-9608-1e6edaf0affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Municipality  Municipality_Bhaktapur  Municipality_Kathmandu  \\\n",
      "0        Kathmandu                   False                    True   \n",
      "1        Bhaktapur                    True                   False   \n",
      "2         Lalitpur                   False                   False   \n",
      "3  Madhyapur Thimi                   False                   False   \n",
      "4         Kirtipur                   False                   False   \n",
      "\n",
      "   Municipality_Kirtipur  Municipality_Lalitpur  Municipality_Madhyapur Thimi  \n",
      "0                  False                  False                         False  \n",
      "1                  False                  False                         False  \n",
      "2                  False                   True                         False  \n",
      "3                  False                  False                          True  \n",
      "4                   True                  False                         False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df_municipalities = pd.DataFrame({\n",
    "    'Municipality': ['Kathmandu', 'Bhaktapur', 'Lalitpur', 'Madhyapur Thimi', 'Kirtipur']\n",
    "})\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoding = pd.get_dummies(df_municipalities['Municipality'], prefix='Municipality')\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "df_encoded = pd.concat([df_municipalities, one_hot_encoding], axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f4ab363-0422-4276-b336-901dd5534cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise concatenation:\n",
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "0  5  7\n",
      "1  6  8\n",
      "\n",
      "Column-wise concatenation:\n",
      "   A  B  A  B\n",
      "0  1  3  5  7\n",
      "1  2  4  6  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "# Row-wise concatenation\n",
    "combined_rows = pd.concat([df1, df2], axis=0)\n",
    "print(\"Row-wise concatenation:\")\n",
    "print(combined_rows)\n",
    "\n",
    "# Column-wise concatenation\n",
    "combined_cols = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nColumn-wise concatenation:\")\n",
    "print(combined_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cf76f2a-db04-49b3-a901-4824efeb7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join:\n",
      "   ID     Name  Score\n",
      "0   2      Bob     85\n",
      "1   3  Charlie     90\n",
      "\n",
      "Left Join:\n",
      "   ID     Name  Score\n",
      "0   1    Alice    NaN\n",
      "1   2      Bob   85.0\n",
      "2   3  Charlie   90.0\n",
      "\n",
      "Outer Join:\n",
      "   ID     Name  Score\n",
      "0   1    Alice    NaN\n",
      "1   2      Bob   85.0\n",
      "2   3  Charlie   90.0\n",
      "3   4      NaN   88.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3, 4], 'Score': [85, 90, 88]})\n",
    "\n",
    "# Inner join\n",
    "inner_merged = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(\"Inner Join:\")\n",
    "print(inner_merged)\n",
    "\n",
    "# Left join\n",
    "left_merged = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(\"\\nLeft Join:\")\n",
    "print(left_merged)\n",
    "\n",
    "# Outer join\n",
    "outer_merged = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(\"\\nOuter Join:\")\n",
    "print(outer_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064042fa-8353-4fee-a4ee-8a51ee3d3f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name           City  age\n",
      "0    Alice       New York   23\n",
      "1      Bob  San Francisco   34\n",
      "2  Charlie    Los Angeles   32\n"
     ]
    }
   ],
   "source": [
    "#1. Load the provided dataset and import in pandas DataFrame.\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46750e35-97bf-493c-b53d-70729d84fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   City    3 non-null      object\n",
      " 2   age     3 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "\n",
      "Columns with dtype = object and their unique values:\n",
      "Column = Name\n",
      "Unique values = ['Alice' 'Bob' 'Charlie']\n",
      "\n",
      "Column = City\n",
      "Unique values = ['New York' 'San Francisco' 'Los Angeles']\n",
      "\n",
      "Total number of null values in each column\n",
      "Name    0\n",
      "City    0\n",
      "age     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2. Check info of the DataFrame and identify following:\n",
    "#(a) columns with dtypes=object\n",
    "#(b) unique values of those columns.\n",
    "#(c) check for the total number of null values in each column.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "\n",
    "df_info = df.info()\n",
    "print(df_info)\n",
    "\n",
    "object_columns = df.select_dtypes(include = ['object']).columns\n",
    "print(\"\\nColumns with dtype = object and their unique values:\")\n",
    "for column in object_columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Column = {column}\")\n",
    "    print(f\"Unique values = {unique_values}\\n\")\n",
    "\n",
    "null_values = df.isnull().sum()\n",
    "print(\"Total number of null values in each column\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35897ea0-296e-4ef4-aba9-9a3e6a07ed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with dtype object have been dropped and the new DataFrame is saved as 'banknumericdata.csv'\n"
     ]
    }
   ],
   "source": [
    "#3. Drop all the columns with dtypes object and store in new DataFrame, also write the DataFrame in ”.csv” with name ”banknumericdata.csv”\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bank.csv')\n",
    "df_numeric = df.select_dtypes(exclude=['object'])\n",
    "df_numeric.to_csv('banknumericdata.csv', index=False)\n",
    "print(\"Columns with dtype object have been dropped and the new DataFrame is saved as 'banknumericdata.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47306ff9-3667-409a-8e9a-615453d68835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             age\n",
      "count   3.000000\n",
      "mean   29.666667\n",
      "std     5.859465\n",
      "min    23.000000\n",
      "25%    27.500000\n",
      "50%    32.000000\n",
      "75%    33.000000\n",
      "max    34.000000\n"
     ]
    }
   ],
   "source": [
    "#4. Read ”banknumericdata.csv” and Find the summary statistics.\n",
    "df_numeric = pd.read_csv('banknumericdata.csv')\n",
    "\n",
    "#Find the summary statistics\n",
    "summary_statistics = df_numeric.describe()\n",
    "print(summary_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075bb546-8764-4779-b7ad-aff6dc9eba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Student ID      180000 non-null  float64\n",
      " 1   Age             180000 non-null  float64\n",
      " 2   Gender          180000 non-null  object \n",
      " 3   Height          180000 non-null  float64\n",
      " 4   Weight          180000 non-null  float64\n",
      " 5   Blood Type      180000 non-null  object \n",
      " 6   BMI             180000 non-null  float64\n",
      " 7   Temperature     180000 non-null  float64\n",
      " 8   Heart Rate      180000 non-null  float64\n",
      " 9   Blood Pressure  180000 non-null  float64\n",
      " 10  Cholesterol     180000 non-null  float64\n",
      " 11  Diabetes        180000 non-null  object \n",
      " 12  Smoking         180000 non-null  object \n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 19.8+ MB\n",
      "Columns with missing values:\n",
      " Student ID        20000\n",
      "Age               20000\n",
      "Gender            20000\n",
      "Height            20000\n",
      "Weight            20000\n",
      "Blood Type        20000\n",
      "BMI               20000\n",
      "Temperature       20000\n",
      "Heart Rate        20000\n",
      "Blood Pressure    20000\n",
      "Cholesterol       20000\n",
      "Diabetes          20000\n",
      "Smoking           20000\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LOQ\\AppData\\Local\\Temp\\ipykernel_5832\\1386568422.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "C:\\Users\\LOQ\\AppData\\Local\\Temp\\ipykernel_5832\\1386568422.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  8611\n",
      "Duplicates have been removed.\n"
     ]
    }
   ],
   "source": [
    "#Problem 2 - Data Imputations:\n",
    "#Complete all the following Task:\n",
    "#• Dataset for the Task: \"medical_student.csv\"\n",
    "#1. Load the provided dataset and import in pandas DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"medical_students_dataset.csv\")\n",
    "\n",
    "#2. Check info of the DataFrame and identify column with missing (null) values.\n",
    "# Check the info of the DataFrame\n",
    "df.info()\n",
    "\n",
    "# Identify columns with missing (null) values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "#3. For the column with missing values fill the values using various techniques we discussed above. Try to explain why did you select the particular methods for particular column.\n",
    "# Fill missing values in numerical column 'Age' with the median\n",
    "if 'Age' in df.columns:\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing values in categorical column 'Gender' with the mode\n",
    "if 'Gender' in df.columns:\n",
    "    df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "\n",
    "# Explanation:\n",
    "# - Numerical columns (like 'Age') are filled with the median to avoid the influence of outliers.\n",
    "# - Categorical columns (like 'Gender') are filled with the mode, which is the most frequent value.\n",
    "\n",
    "#4. Check for any duplicate values present in Dataset and do necessary to manage the duplicate items.\n",
    "#{Hint: dataset.duplicated.sum()}\n",
    "# Check for duplicate values\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", duplicate_count)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Duplicates have been removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01acd737-1e91-48a8-84ae-eb3237f7efa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fare: 84.1546875\n",
      "Median Fare: 60.287499999999994\n",
      "Maximum Fare: 512.3292\n",
      "Minimum Fare: 0.0\n"
     ]
    }
   ],
   "source": [
    "#3.2 Exercises - Data Cleaning and Transformations with ”Titanic Dataset”:\n",
    "#Dataset Used: \"titanic.csv\"\n",
    "#Problem - 1:\n",
    "#Create a DataFrame that is subsetted for the columns ’Name’, ’Pclass’, ’Sex’, ’Age’, ’Fare’, and ’Survived’.\n",
    "#Retain only those rows where ’Pclass’ is equal to 1, representing first-class passengers. What is the mean,\n",
    "#median, maximum value, and minimum value of the ’Fare’ column?\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Subset the DataFrame for the specified columns\n",
    "df_subset = df[['Name', 'Pclass', 'Sex', 'Age', 'Fare', 'Survived']]\n",
    "\n",
    "# Retain only rows where Pclass is equal to 1\n",
    "df_first_class = df_subset[df_subset['Pclass'] == 1]\n",
    "\n",
    "# Calculate mean, median, maximum, and minimum values of the 'Fare' column\n",
    "fare_mean = df_first_class['Fare'].mean()\n",
    "fare_median = df_first_class['Fare'].median()\n",
    "fare_max = df_first_class['Fare'].max()\n",
    "fare_min = df_first_class['Fare'].min()\n",
    "\n",
    "print(f\"Mean Fare: {fare_mean}\")\n",
    "print(f\"Median Fare: {fare_median}\")\n",
    "print(f\"Maximum Fare: {fare_max}\")\n",
    "print(f\"Minimum Fare: {fare_min}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b9230e-40fe-4fe0-b51d-19f73d9fcb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in the 'Age' column: 30\n",
      "Number of null values in the 'Age' column after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "#Problem - 2:\n",
    "#How many null values are contained in the ’Age’ column in your subsetted DataFrame? Once you’ve found\n",
    "#this out, drop them from your DataFrame.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Subset the DataFrame for the specified columns\n",
    "df_subset = df[['Name', 'Pclass', 'Sex', 'Age', 'Fare', 'Survived']]\n",
    "\n",
    "# Retain only rows where Pclass is equal to 1\n",
    "df_first_class = df_subset[df_subset['Pclass'] == 1]\n",
    "\n",
    "# Count the number of null values in the 'Age' column\n",
    "null_values_age = df_first_class['Age'].isnull().sum()\n",
    "print(f\"Number of null values in the 'Age' column: {null_values_age}\")\n",
    "\n",
    "# Drop rows with null values in the 'Age' column\n",
    "df_first_class = df_first_class.dropna(subset=['Age'])\n",
    "\n",
    "# Verify that the null values have been dropped\n",
    "null_values_after_drop = df_first_class['Age'].isnull().sum()\n",
    "print(f\"Number of null values in the 'Age' column after dropping: {null_values_after_drop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd0549-423c-4e53-a465-679c37fd15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem - 3:\n",
    "\n",
    "The ’Embarked’ column in the Titanic dataset contains categorical data representing the ports of embarka-\n",
    "tion:\n",
    "\n",
    "• ’C’ for Cherbourg\n",
    "• ’Q’ for Queenstown\n",
    "• ’S’ for Southampton\n",
    "Task:\n",
    "1. Use one-hot encoding to convert the ’Embarked’ column into separate binary columns (’Embarked C’,\n",
    "’Embarked Q’, ’Embarked S’).\n",
    "2. Add these new columns to the original DataFrame.\n",
    "3. Drop the original ’Embarked’ column.\n",
    "4. Print the first few rows of the modified DataFrame to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b851e66f-43ed-46dc-872a-888f8189df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0      0         A/5 21171   7.2500   NaN       False       False        True  \n",
      "1      0          PC 17599  71.2833   C85        True       False       False  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN       False       False        True  \n",
      "3      0            113803  53.1000  C123       False       False        True  \n",
      "4      0            373450   8.0500   NaN       False       False        True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Perform one-hot encoding on the 'Embarked' column\n",
    "df_encoded = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "\n",
    "# Add the new one-hot encoded columns to the original DataFrame\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Drop the original 'Embarked' column\n",
    "df.drop('Embarked', axis=1, inplace=True)\n",
    "\n",
    "# Print the first few rows to verify the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f0786e-9290-45a4-b912-e85c7e48c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Survival Rates by Gender:\n",
      "Sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "Summary Statistics for Survival Rates by Gender:\n",
      "        count      mean       std  min  25%  50%  75%  max\n",
      "Sex                                                       \n",
      "female  314.0  0.742038  0.438211  0.0  0.0  1.0  1.0  1.0\n",
      "male    577.0  0.188908  0.391775  0.0  0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#Problem - 4:\n",
    "#Compare the mean survival rates (’Survived’) for the different groups in the ’Sex’ column. Draw a visual-\n",
    "#ization to show how the survival distributions vary by gender.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Calculate mean survival rates by gender\n",
    "mean_survival_by_gender = df.groupby('Sex')['Survived'].mean()\n",
    "print(\"Mean Survival Rates by Gender:\")\n",
    "print(mean_survival_by_gender)\n",
    "\n",
    "# Display the summary statistics for survival rates by gender\n",
    "survival_stats_by_gender = df.groupby('Sex')['Survived'].describe()\n",
    "print(\"\\nSummary Statistics for Survival Rates by Gender:\")\n",
    "print(survival_stats_by_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1fefc5-9df1-4b82-a4bc-2e1fe4edccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rates by Gender and Port of Embarkation:\n",
      "Sex     Embarked\n",
      "female  C           0.876712\n",
      "        Q           0.750000\n",
      "        S           0.689655\n",
      "male    C           0.305263\n",
      "        Q           0.073171\n",
      "        S           0.174603\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Problem - 5:\n",
    "\n",
    "#Draw a visualization that breaks your visualization from Exercise 3 down by the port of embarkation (’Em-\n",
    "#barked’). In this instance, compare the ports ’C’ (Cherbourg), ’Q’ (Queenstown), and ’S’ (Southampton).\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "# Perform one-hot encoding on the 'Embarked' column\n",
    "df_encoded = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "\n",
    "# Add the new one-hot encoded columns to the original DataFrame\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Group by 'Sex' and 'Embarked' to calculate survival rates\n",
    "survival_rates = df.groupby(['Sex', 'Embarked'])['Survived'].mean()\n",
    "print(\"Survival Rates by Gender and Port of Embarkation:\")\n",
    "print(survival_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642cd7c-16f9-449e-8e27-d91faa9099d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
